---
title: Lived Experiences with ChatGPT for Mental Health Support
date: "2026-01"
author: "Ongoing"
date-format: "MMM YYYY"
published-title: "started"
author-title: "state"
description: "PI: Gihun Im"
categories:
  - ChatGPT
  - genAI
format: html
editor: visual
filters:
  - highlight-text
---

![](chatgpt.jpg){fig-align="center"}

Young adults increasingly use generative AI (genAI) chatbots for emotional support, frequently describing these interactions as similar to human conversation. Although ChatGPT was not designed for mental health concerns, its accessibility and personalization have made it a widely used platform for this purpose. Yet, critical incidents have prompted concerns from the American Psychological Association (APA, 2025)[^1] regarding the dangers of unregulated genAI in mental health contexts.

[^1]: American Psychological Association. (2025). *APA health advisory on the use of generative AI chatbots and wellness applications for mental health*. https://www.apa.org/topics/artificial-intelligence-machine-learning/health-advisory-ai-chatbots-wellness-apps-mental-health.pdf

Previous studies on mental health chatbots have primarily relied on experimental settings focusing on symptom change, failing to capture usersâ€™ lived experiences with ongoing, unstructured interactions. Existing reviews also predate recent advances in human-like conversation and often conflate clinically supervised bots with general-purpose systems.

This systematic review utilizes a mixed-method meta-analysis (Levitt, 2024)[^2] following PRISMA guidelines to prioritize diverse lived experiences. We are synthesizing quantitative and qualitative findings to determine how users describe their support experiences, identify influential features of ChatGPT, assess perceived benefits and risks, and evaluate reported psychological outcomes.

[^2]: Levitt, H. M. (2024). How to conduct an integrative mixed methods meta-analysis: A tutorial for the systematic review of quantitative and qualitative evidence. *Psychological Methods*. Advance online publication. https://doi.org/10.1037/met0000675

Results will help psychologists understand how ChatGPT shapes help-seeking behaviors, contribute to responsible governance, and move future research beyond clinical pilot studies to capture the reality of unstructured AI use.

[We have been invited to submit this work to the special issue of *Professional Psychology: Research & Practice*.]{color="#FFD479"}
